# カスタムデータの作り方

このドキュメントでは、mocopiおよびBlenderで取得したモーションデータをMotionBERTで使用できる形式に変換し、トレーニングデータとして準備する方法を説明します。

## データフォーマット

### Pickle（.pkl）ファイル構造

各モーションサンプルは Python の辞書型として pickle 形式で保存します。

**必須キー:**

```python
{
    "data_label": numpy.ndarray,   # 3D ground-truth: shape (T, J, 3)
    "data_input": numpy.ndarray    # 2D detections: shape (T, J, 3)
}
```

**各要素の説明:**

- **data_label** (T, J, 3):
  - 3D座標（グラウンドトゥルース）
  - T = フレーム数（デフォルト: 243フレーム）
  - J = ジョイント数（17個の関節）
  - 3 = [x, y, z] 座標値（単位: mm）
  - dtype: float32

- **data_input** (T, J, 3):
  - 2D検出座標
  - 3 = [x_2d, y_2d, confidence]
    - x_2d, y_2d = 2D画像座標（ピクセル または 正規化座標）
    - confidence = 検出の信頼度スコア（0.0～1.0）
  - dtype: float32
  - 注: 2D検出データがない場合は None を指定可能（その場合、configで `gt_2d: True` または `synthetic: True` を設定）

### 最小限のサンプル作成例

```python
import pickle
import numpy as np
import os

def create_sample(T=243, J=17):
    """カスタムモーションサンプルを作成"""
    # 3D座標（実際のmocopiやBlenderデータに置き換え）
    data_label = np.random.randn(T, J, 3).astype(np.float32)
    
    # 2D座標（3DからのXY投影 + 信頼度）
    data_input = np.concatenate([
        data_label[..., :2],                        # XY座標を3Dから取得
        np.ones((T, J, 1), dtype=np.float32)       # 信頼度 = 1.0
    ], axis=-1)
    
    return {
        "data_label": data_label,
        "data_input": data_input
    }

# 実行例
sample = create_sample()
print(f"data_label shape: {sample['data_label'].shape}")  # (243, 17, 3)
print(f"data_input shape: {sample['data_input'].shape}")   # (243, 17, 3)
```

## ファイル配置

### ディレクトリ構造

カスタムデータは以下のディレクトリ構造で配置してください:

```
data/
└── motion3d/
    └── mocopi_blender/                    # data_root で指定
        ├── cam1/                          # subset_list に含める（仮想カメラ1）
        │   ├── train/
        │   │   ├── sample_0001.pkl
        │   │   ├── sample_0002.pkl
        │   │   └── ...
        │   └── test/
        │       ├── sample_0101.pkl
        │       ├── sample_0102.pkl
        │       └── ...
        ├── cam2/                          # 仮想カメラ2
        │   ├── train/
        │   │   └── ...
        │   └── test/
        │       └── ...
        └── cam3/                          # 仮想カメラ3
            ├── train/
            │   └── ...
            └── test/
                └── ...
```

**重要:** train/ と test/ は分けて配置してください。train/ に test/ のファイルが混在するとデータリークが発生します。

### ファイル配置の自動化スクリプト

以下のスクリプトでカスタムデータを自動生成・配置できます:

```python
import pickle
import numpy as np
import os

def create_custom_dataset(
    data_root="data/motion3d/mocopi_blender",
    subset_names=["cam1", "cam2", "cam3"],
    num_train_samples=10,
    num_test_samples=2,
    T=243,
    J=17
):
    """
    カスタムモーションデータセットを自動作成・配置
    
    Args:
        data_root: データの保存先ルートディレクトリ
        subset_names: カメラ名のリスト（Blenderの仮想カメラに対応）
        num_train_samples: 各subsetのトレーニングサンプル数
        num_test_samples: 各subsetのテストサンプル数
        T: フレーム数（デフォルト: 243）
        J: ジョイント数（デフォルト: 17）
    """
    
    for subset in subset_names:
        # ディレクトリ作成
        train_dir = os.path.join(data_root, subset, "train")
        test_dir = os.path.join(data_root, subset, "test")
        os.makedirs(train_dir, exist_ok=True)
        os.makedirs(test_dir, exist_ok=True)
        
        print(f"\n[{subset}] データを作成中...")
        
        # トレーニングサンプル
        for i in range(num_train_samples):
            data_label = np.random.randn(T, J, 3).astype(np.float32)
            data_input = np.concatenate([
                data_label[..., :2],
                np.ones((T, J, 1), dtype=np.float32)
            ], axis=-1)
            
            sample_dict = {
                "data_label": data_label,
                "data_input": data_input
            }
            
            path = os.path.join(train_dir, f"sample_{i:04d}.pkl")
            with open(path, "wb") as f:
                pickle.dump(sample_dict, f)
            print(f"  ✓ {path}")
        
        # テストサンプル
        for i in range(num_test_samples):
            data_label = np.random.randn(T, J, 3).astype(np.float32)
            data_input = np.concatenate([
                data_label[..., :2],
                np.ones((T, J, 1), dtype=np.float32)
            ], axis=-1)
            
            sample_dict = {
                "data_label": data_label,
                "data_input": data_input
            }
            
            path = os.path.join(test_dir, f"sample_{1000+i:04d}.pkl")
            with open(path, "wb") as f:
                pickle.dump(sample_dict, f)
            print(f"  ✓ {path}")
    
    print(f"\n✓ データセット作成完了: {data_root}")

# 実行例
if __name__ == "__main__":
    create_custom_dataset(
        data_root="data/motion3d/mocopi_blender",
        subset_names=["cam1", "cam2", "cam3"],
        num_train_samples=10,
        num_test_samples=2
    )
```

実行方法:
```powershell
cd c:\Users\user\Desktop\workplace\MotionBERT
python create_dataset.py
```

## Configファイルの設定

カスタムデータセットを使用するため、config YAML ファイルを以下のように編集します。

### 変更対象

`configs/pose3d/MB_ft_h36m_global_lite.yaml` などの config ファイルで、Data セクションを編集:

```yaml
# Data
data_root: data/motion3d/mocopi_blender/          # ← カスタムデータの保存先に変更
subset_list: [cam1, cam2, cam3]                   # ← 使用するカメラ名に変更
dt_file: custom_motion.pkl                        # ← 評価用メタデータ（以下参照）
clip_len: 243                                      # ← フレーム数（変更不要）
data_stride: 81
rootrel: False
sample_stride: 1
num_joints: 17                                     # ← ジョイント数（変更不要）
no_conf: False
gt_2d: False                                       # ← False推奨（data_inputを使用）
```

### 各パラメータの説明

| パラメータ | 説明 |
|-----------|------|
| `data_root` | カスタムデータの保存先ルートディレクトリ |
| `subset_list` | 使用するカメラ名（複数指定可。Blenderの仮想カメラに対応） |
| `dt_file` | 評価用メタデータファイル（下記参照） |
| `clip_len` | 1クリップのフレーム数（学習データのT値に一致させる） |
| `num_joints` | ジョイント数（17で固定） |
| `gt_2d` | Trueの場合、data_inputをdata_labelから自動生成 |
| `synthetic` | Trueの場合、3D拡張を適用して2Dを合成 |
| `flip` | Trueの場合、トレーニング時にランダムに水平反転 |

## 評価用メタデータ（dt_file）

`evaluate()` 関数を使用する場合、評価用のメタデータファイル（dt_file）が必要です。

### 最小限のメタデータ作成例

```python
import pickle
import numpy as np
import os

T, J = 243, 17

dt_dict = {
    "train": {
        "joints_2.5d_image": np.random.randn(10, T, J, 3).astype(np.float32),
        "action": ["walking"] * 10,
        "source": ["mocopi"] * 10,
        "2.5d_factor": np.ones(10, dtype=np.float32)
    },
    "test": {
        "joints_2.5d_image": np.random.randn(2, T, J, 3).astype(np.float32),
        "action": ["walking"] * 2,
        "source": ["mocopi"] * 2,
        "2.5d_factor": np.ones(2, dtype=np.float32)
    }
}

os.makedirs("data/motion3d", exist_ok=True)
with open("data/motion3d/custom_motion.pkl", "wb") as f:
    pickle.dump(dt_dict, f)

print("✓ Created custom_motion.pkl")
```

## トレーニング開始

config を設定後、以下のコマンドでトレーニングを開始:

```powershell
cd c:\Users\user\Desktop\workplace\MotionBERT
python train.py --config configs/pose3d/custom_config.yaml -c checkpoint/custom
```

## 注意事項

- **フレーム数**: `clip_len` とデータの T（フレーム数）を一致させてください
- **ジョイント数**: `num_joints` は 17 に固定
- **data_input の置き方**: test/ フォルダに含める場合、None でも OK（`gt_2d: True` で自動合成）
- **ファイル命名**: .pkl ファイル名は自由（sorted() で読み込まれるため）
- **データ型**: float32 を使用してください

